{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebvqJaNU9bkH"
      },
      "source": [
        "# Wprowadzenie do sieci neuronowych i uczenia maszynowego\n",
        "\n",
        "## Lab 5a: Podstawowe moduły w PyTorch, sieci konwolucyjne\n",
        "\n",
        "---\n",
        "\n",
        "**Prowadzący:** Iwo Błądek, Anna Labijak-Kowalska<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uwaga\n",
        "\n",
        "* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n",
        "* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji.\n"
      ],
      "metadata": {
        "id": "o8aSyboqZ40M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlq47LA0BuBB"
      },
      "source": [
        "## Cel ćwiczeń:\n",
        "\n",
        "* zapoznanie się z pojęciem **zbioru danych** i jego charakterystyką,\n",
        "* wykorzystanie podstawowych warstw neuronowych,\n",
        "* implementacja procesu uczenia sieci neuronowej + *good practices*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z8ToIOrDr7A8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041fa46b-a692-4b97-f814-c9a9a77c3f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s10XO61Fn57k"
      },
      "source": [
        "## Zbiór danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNwfaIiuy6ar"
      },
      "source": [
        "### Wprowadzenie oraz popularne zbiory danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmzwK1KIvl_t"
      },
      "source": [
        "Odpowiednie przygotowanie zbioru danych odgrywa znaczącą rolę w uczeniu sieci neuronowych. Zazwyczaj zbiory danych zawierają 3 pozbiory:\n",
        "\n",
        "* treningowy - wykorzystywany do uaktualniania wag modelu neuronowego,\n",
        "* walidacyjny - do oceny modelu po każdej **epoce**,\n",
        "* testowy - do porównania modelu z innymi rozwiązaniami.\n",
        "\n",
        "**Uwaga:** bardzo często popularne zbiory danych nie posiadają wyróżnionego zbioru testowego, ponieważ nie prowadzą tzw. **leaderboard**.\n",
        "\n",
        "Najpopularniejsze zbiory danych:\n",
        "\n",
        "* **MNIST**,\n",
        "* eMNIST,\n",
        "* Caltech 101/256,\n",
        "* Cityscapes,\n",
        "* Kitty,\n",
        "* LFW Face Dataset,\n",
        "* ImageNet\n",
        "\n",
        "Więcej informacji: [wiki](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research) [kaggle](https://www.kaggle.com/datasets) [google](https://toolbox.google.com/datasetsearch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWwP2RtTy-9o"
      },
      "source": [
        "### Obsługa zbioru danych w PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29POyzqin9L1"
      },
      "source": [
        "Kod do przetwarzania danych może stać się nieczytelny i trudny do utrzymania; idealnie chcielibyśmy, aby kod związany z naszym zestawem danych był oddzielony od kodu, który odpowiada za uczenie modelu. PyTorch udostępnia dwie klasy do obsługi danych: `torch.utils.data.DataLoader` i `torch.utils.data.Dataset`, które pozwalają na użycie zarówno gotowych zestawów danych, jak i własnych. `Dataset` przechowuje próbki i ich odpowiadające etykiety, a `DataLoader` jest swego rodzaju nakładką na obiekt `Dataset`, umożliwiając łatwy dostęp do próbek - ładowanie danych, dzielenie danych na podzbiory (_ang. batch_). [link](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDh89pFDzGca"
      },
      "source": [
        "#### Tworzenie zbioru danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9S59kIwgz5x1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13cfbe7-c86f-4fb1-b642-b268566151bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2ea1c1efc034>:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  tensor_x = torch.Tensor(x)\n"
          ]
        }
      ],
      "source": [
        "dataset_size = 10\n",
        "\n",
        "# zbiór danych składający się z losowych obrazków o rozmiarze (32, 32, 3) oraz etykiet po kolei od 0 do dataset_size\n",
        "x = [np.random.uniform(size=(32, 32, 3)) for _ in range(dataset_size)]\n",
        "y = [i for i in range(dataset_size)]\n",
        "\n",
        "tensor_x = torch.Tensor(x)\n",
        "tensor_y = torch.Tensor(y)\n",
        "\n",
        "# utworzenie \"iteratora\" zbioru danych\n",
        "dataset = torch.utils.data.TensorDataset(tensor_x, tensor_y)\n",
        "dataloader = torch.utils.data.DataLoader(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latEGDXR1BDT"
      },
      "source": [
        "#### Iterowanie po zbiorze danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mJZo9pGz1EX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d254efd1-1525-4038-d31c-3e65ac591404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 32, 3]) tensor([0.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([1.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([2.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([3.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([4.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([5.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([6.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([7.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([8.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([9.])\n"
          ]
        }
      ],
      "source": [
        "for x, y in dataloader:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8xxrDkx1b_r"
      },
      "source": [
        "#### Tasowanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yzQhivcx1wjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61882e0-22fa-4dea-ccd2-a8fbe2c6e017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 32, 3]) tensor([7.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([2.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([3.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([1.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([9.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([6.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([5.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([8.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([0.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([4.])\n"
          ]
        }
      ],
      "source": [
        "dataloader_shuffled = torch.utils.data.DataLoader(dataset, shuffle=True)\n",
        "\n",
        "for x, y in dataloader_shuffled:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUFB46tu15qP"
      },
      "source": [
        "#### Mapowanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "vxLq1Jwa17HN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50195f18-ba6b-43c1-b1f6-b1f402f45f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 32, 3]) tensor([0.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([2.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([4.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([6.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([8.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([10.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([12.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([14.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([16.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([18.])\n"
          ]
        }
      ],
      "source": [
        "class MappedDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dataset, transform_func):\n",
        "    self.dataset = dataset\n",
        "    self.transform_func = transform_func\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data, label = self.dataset[idx]\n",
        "    return self.transform_func(data, label)\n",
        "\n",
        "\n",
        "def map(x, y):\n",
        "  y = y * 2\n",
        "  return x, y\n",
        "\n",
        "\n",
        "dataset_mapped = MappedDataset(dataset, map)\n",
        "dataloader_mapped = torch.utils.data.DataLoader(dataset_mapped)\n",
        "\n",
        "for x, y in dataloader_mapped:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TUb4toF2T-8"
      },
      "source": [
        "#### Filtrowanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3ZOTi5mz2Vpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d57ea0f-d33b-41f8-d489-021ffff1a2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 32, 3]) tensor([6.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([7.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([8.])\n",
            "torch.Size([1, 32, 32, 3]) tensor([9.])\n"
          ]
        }
      ],
      "source": [
        "class FilteredDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dataset, threshold):\n",
        "    self.filtered_data = [\n",
        "      (data, label) for data, label in dataset if label > threshold\n",
        "    ]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filtered_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.filtered_data[idx]\n",
        "\n",
        "\n",
        "dataset_filtered = FilteredDataset(dataset, 5)\n",
        "\n",
        "dataloader_filtered = torch.utils.data.DataLoader(dataset_filtered)\n",
        "\n",
        "for x, y in dataloader_filtered:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhZmXSZJ2fc3"
      },
      "source": [
        "#### Grupowanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FLaNPS6A2iK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efdf658-aa36-4406-d8dc-260036394a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 32, 32, 3]) tensor([0., 1., 2., 3., 4.])\n",
            "torch.Size([5, 32, 32, 3]) tensor([5., 6., 7., 8., 9.])\n"
          ]
        }
      ],
      "source": [
        "dataloader_batch = torch.utils.data.DataLoader(dataset, batch_size=5)\n",
        "\n",
        "for x, y in dataloader_batch:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_98O2Zsr2xEP"
      },
      "source": [
        "#### Składanie wielu operacji na raz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q2o3BqWb2z27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0de046-6584-4cdc-c9c0-9832dd7c84b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9264) torch.Size([5, 32, 32, 3]) tensor([10., 12., 14., 16., 18.])\n",
            "tensor(0.9849) torch.Size([1, 32, 32, 3]) tensor([8.])\n"
          ]
        }
      ],
      "source": [
        "dataset_mix = MappedDataset(dataset, map)\n",
        "dataset_mix = FilteredDataset(dataset_mix, 6)\n",
        "\n",
        "dataloader_mix = torch.utils.data.DataLoader(dataset_mix, shuffle=True, batch_size=5)\n",
        "\n",
        "for x, y in dataloader_mix:\n",
        "  print(x[0, 0, 0, 0], x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TJaDyXCA9Qe"
      },
      "source": [
        "### Popularne zbiory danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp29iNwaBBhw"
      },
      "source": [
        "Biblioteka PyTorch zawiera gotowe funkcje wczytujące dla niektórych zbiorów danych. Większość gotowych zbiorów danych możemy znaleźć w bibliotece *torchvision*. Tutaj możesz znaleźć dokładną listę dostępnych zbiorów danych - [link](https://pytorch.org/vision/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQp1MMjzB9Di"
      },
      "source": [
        "Jednym z popularniejszych zbiorów danych jest MNIST. Jest to zbiór zawierający cyfry pochodzące z pisma odręcznego wraz z ich przypisanymi etykietami ('1', '2', etc.). Poniżej przykładowe pobranie i wykorzystanie zbioru MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dcggguYcB-8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79551142-eabc-4296-f1de-29f186797684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:11<00:00, 901kB/s] \n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.08MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.62MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OJEqdWYeHhg-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "eb6c819f-6887-4c78-f310-bb5c07194f44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAKSCAYAAABMVtaZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANXtJREFUeJzt3XnclmPeP/DjrqSNqBSpKKGnhGxjGdswPWHKGjJDZAYpxthmiJcm1GMZZky2GdmTLI8fIrJlG1Fk7KKXsUS2JK1a7t8f84znMY7jrquu+7ruruP9/vN79D3Pb3Wf9ensPo6rqrq6ujoAAFDx6pV7AAAASkPwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4FcHTJ48OQwePDh069YtNG3aNHTo0CEceuihYdq0aeUeDSrKO++8Ew4//PDQrl270KRJk9ClS5cwbNiwMH/+/HKPBhVl7ty54bzzzgu9evUKLVq0CFVVVeHGG28s91iEEBqUewBCuOiii8Kzzz4b+vbtG7bccsswc+bMMHLkyLDNNtuESZMmhS222KLcI8Jq78MPPww77LBDaN68eRg8eHBo0aJFeO6558J5550XXnzxxXDvvfeWe0SoGF988UUYNmxY6NChQ9hqq63CxIkTyz0S/0PwqwNOPfXUcNttt4WGDRt+VzvssMNC9+7dw3/913+FW2+9tYzTQWW45ZZbwuzZs8MzzzwTunXrFkII4bjjjgvLli0LN998c/jqq6/CuuuuW+YpoTJssMEG4ZNPPgnrr79+mDJlSth+++3LPRL/Q/CrA3beeecf1DbddNPQrVu38Oabb5ZhIqg8c+bMCSGE0KZNm+/VN9hgg1CvXr3v/cMLWDVrrrlmWH/99cs9BhG+x6+Oqq6uDp9++mlo1apVuUeBirDHHnuEEEI49thjw8svvxw+/PDDMHbs2HD11VeHk08+OTRt2rS8AwKUgOBXR40ePTrMmDEjHHbYYeUeBSpCr169wvnnnx8eeeSR0KNHj9ChQ4dw+OGHh5NOOilcfvnl5R4PoCT8V28d9NZbb4VBgwaFnXbaKfTv37/c40DF2HjjjcNuu+0WDj744NCyZcvwwAMPhOHDh4f1118/DB48uNzjAdQ6wa+OmTlzZthvv/1C8+bNw1133RXq169f7pGgItx+++3huOOOC9OmTQvt2rULIYRw0EEHhWXLloXf/va3oV+/fqFly5ZlnhKgdvmv3jrk66+/Dvvss0+YPXt2eOihh0Lbtm3LPRJUjKuuuir06NHju9D3L3369Anz588PU6dOLdNkAKUj+NURCxcuDL179w7Tpk0L48aNC127di33SFBRPv3007B06dIf1BcvXhxCCGHJkiWlHgmg5AS/OmDp0qXhsMMOC88991y48847w0477VTukaDibLbZZmHq1Kk/+EScMWPGhHr16oUtt9yyTJMBlI7v8asDTjvttHDfffeF3r17h1mzZv3gwOZf/OIXZZoMKscZZ5wRxo8fH3bdddcwePDg0LJlyzBu3Lgwfvz48Mtf/tK3VkCRjRw5MsyePTt8/PHHIYQQ7r///vDRRx+FEEI46aSTQvPmzcs5Xraqqqurq8s9RO722GOP8OSTTybX/RZBcbzwwgth6NChYerUqeHLL78MHTt2DP379w9nnnlmaNDAv4OhmDbeeOPw/vvvR9fee++9sPHGG5d2IEIIgh8AQDZ8jx8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIhOAHAJCJFT6xtKqqqjbngLKoi8dYetaoRJ41KI3lPWve+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGSiQbkHWJ106tQpWr///vuTPV27do3Wq6urizLTv7z++uvR+qWXXprsuemmm4o6AwBQt3njBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADJRVb2C54pUVVXV9ix13m9+85tovaYjU8rtm2++Sa6ljpr5+OOPa2ucOqfYx+oUg2etdBo2bBitN2vWrGjXCiGEBx54IFrfZpttkj2pr81p06Yle4YMGRKt33333cmeUvGs5a19+/bR+mOPPZbs2XTTTaP1kSNHJntOOumkwgarQMt71rzxAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBM2NX7bw488MDk2m233Rat17Sbry6bOnVqtL7vvvsmez777LPaGqcs7DSsHG3atInWjz766GTPnnvuGa3/9Kc/LcZIJff2229H64MGDUr2PPHEE7U1zvd41vK2yy67ROtPPfVUwddKfZ2HkD6tIid29QIAEEIQ/AAAsiH4AQBkQvADAMiE4AcAkAnBDwAgEw3KPUC5bLbZZtH62LFjkz3169eP1ufNm5fs6d+/f7T+4IMPJnsGDx4crR9xxBHJnq233jq5ltKjR49offTo0cme1fWYC1Yv9erF/0165plnJnuOP/74aL1Dhw5FmWl5pkyZklxLHT+RegZDWLljKTbffPNovVGjRgVfC4rpnHPOKfcI/A9v/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE9nu6v3222+j9XfffTfZs/7660frL730UrLnnnvuKWywEMIf/vCHaP3OO+9M9jz//PPReuvWrQu+f4MG2X5ZUEekdt1feOGFJbn/M888k1y7+OKLo/UJEyYke+66665o3QfKU0k23HDD5FrHjh1LOAk18cYPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZCLbczv+8Y9/ROs1Ha/Qs2fPaL2mYxyK6YMPPkiuLVq0qCQzQCl06NChaNd66qmnkmupo1meeOKJZM/ChQuj9f79+yd7fvaznyXXUiZOnBit33vvvcme7bffPlqv6dcAiqVfv37JtU033bTg682aNStaHzRoUMHX4n954wcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmch2V+/KKNXu3ZUxZcqUaL19+/YFX6tVq1bJtY022ihaf//99wu+D5TC/Pnzk2vjx48v+Hpbb711tH7dddcVfK0vvvgiuXbLLbdE6zfeeGPB94FS2H///Yt6vY8++ihar2nXPcvnjR8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIhONcKsRf/vKXaP3AAw8s+Fpdu3ZNru26667RuuNcKKZnn302Wl+2bFmyp169+L9ja/p67tSpU7T+3nvvJXuaNWuWXCvUHXfckVxzbAu5e+2118o9QkXyxg8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMmFXL1DnLFy4MFp/9NFHkz09e/aM1jt06JDsGT9+fLR+7rnnJnsGDhwYrad2FYcQwuzZs6P1kSNHJnugrmrTpk203qJFi6Le58477yzq9fgnb/wAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJhznUiG22mqrol3ryy+/TK599NFHRbsPpCxdujRaP/LII5M906ZNi9abN2+e7OncuXO0PmbMmBqmi1u8eHFy7Xe/+120/vbbbxd8Hyi3Hj16ROtdunQp+FpvvPFGcu2pp54q+Hosnzd+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJu3orxKBBg4p2rddffz25NnHixKLdBwr1xRdfJNeuvPLKaP3ss8+urXG+54477kiuPfLIIyWZAUqhY8eORbvW/Pnzk2uzZ88u2n34X974AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEw4zqUAZ5xxRrS+cOHCZM+f//zn2hoH+D/+8pe/ROvHHntssqdNmzYF32fKlCnR+jnnnJPs+eCDDwq+D9RVxxxzTNGudcMNNxTtWqwYb/wAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBMVvau3bdu2ybWbbropWt90002TPRtuuGG0vmzZsmTPaaedVlA9hBCeeuqpaH2ttdZK9jRq1Ci5Vqjf/e53RbsWlMpuu+0WrTdt2rQk91933XWTa3b1srrZcccdk2s1/T2ZMnfu3Gj95ZdfLvharBpv/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmKvo4l7FjxybXdt5556Ldp169dH5u3759tH7HHXcke5599tlofZ111kn2rLfeesm1lPvuuy9af+ONNwq+FpTCfvvtl1y7/PLLo/VmzZoVdYbtttsuWl+ZZxDqqjZt2iTX1l577YKv9/e//z1anzRpUsHXYtV44wcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmaiIXb177713tP6jH/0o2TNr1qxo/frrry/4/n379k2ubbTRRgVfb5dddim4J2XRokXJteuuuy5a/+abb4p2f2jSpEm0XtNu+DvvvDNaTz3rNUl9OHwIIbzyyivR+srs+j/55JOTa48++mjB14NK0rhx42i9adOmyZ558+bV1jhZ88YPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZKIijnPp06dPtF6/fv1kT2qb+J///Odkz0cffVRwz1lnnRWtn3DCCcmeYlq8eHFyLXVsS+r4jRBCmD9//irPROWp6QPdU0eZdO3ateD7LFu2LLk2ceLEaP2nP/1psufSSy+N1lfmOBeoJOuuu25Rr9etW7dofdttt032PPXUU0WdgX/yxg8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMlERu3qXLFlScE/79u2j9XvuuSfZ8+abbxZ8n6222qrgnmJq1qxZcu2JJ56I1rt3757seeONN1Z5JlZfG2+8cbQ+duzYZM/K7N6trq6O1lM7d0NI796t6Rn4yU9+UtBcNRk3blzRrgWl0rhx42j9jDPOKOp9pkyZEq3buVt63vgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATFRVp85N+PcfWFVV27MU3YIFC5JrDRs2LOEkq5fp06cn13r37h2tv/3227U1Tq1awS//kir3s7bjjjsm11LHHbVu3brg+8yYMSO59vjjj0frN910U7KnVatW0fppp52W7Nl+++2TaykffvhhtN65c+dkz8ocOVVpPGt109FHHx2tjxo1qqj3Oeuss6L1iy++uKj3YfnPmjd+AACZEPwAADIh+AEAZELwAwDIhOAHAJCJBuUeoDadfPLJybVLLrkkWl9rrbVqa5wVtnjx4mh96tSpyZ6bb745Wh82bFiyp0WLFtH6Jptskuw59NBDo/Xzzz8/2UPdlNrZXtPXzMrs3k1ZY401kmtNmzaN1h999NGi3X9lTZgwIVqvi7tWYXl++9vfluQ+kydPLsl9WD5v/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmqqpX8AyCSvsw65/97GfR+qBBg5I9PXv2LNr9Tz/99OTazJkzo/UxY8YUfJ/UzzOEEO69996Cr7dw4cJoPXX8Rl1XF4/gKNWztueee0brdeHIlHIbOnRocm3EiBHR+pIlS2ppmsqQ87NWl7355pvR+mabbVbwtWr6Pd5rr72i9SeffLLg+1Cz5T1r3vgBAGRC8AMAyITgBwCQCcEPACATgh8AQCay3dULIeS907Bx48bR+tVXX53sOfLII2trnBUyb9685NqVV15Z8PVGjx4drad2OoYQwtKlSwu+D3k/a3XZn//852j9xBNPLPha55xzTnIttRue4rOrFwCAEILgBwCQDcEPACATgh8AQCYEPwCATAh+AACZcJwLWXPEBJSGZw1Kw3EuAACEEAQ/AIBsCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJqqqq6uryz0EAAC1zxs/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcGvDnjnnXfC4YcfHtq1axeaNGkSunTpEoYNGxbmz59f7tGgYkyePDkMHjw4dOvWLTRt2jR06NAhHHrooWHatGnlHg0qyuuvvx769u0bOnXqFJo0aRJatWoVdtttt3D//feXezRCCFXV1dXV5R4iZx9++GHYcsstQ/PmzcMJJ5wQWrRoEZ577rlw4403hj59+oR777233CNCRTjkkEPCs88+G/r27Ru23HLLMHPmzDBy5Mgwd+7cMGnSpLDFFluUe0SoCA8++GC44oorwk477RTatm0b5s+fH+6+++7w9NNPh2uvvTYcd9xx5R4xa4JfmQ0fPjwMGTIkvPbaa6Fbt27f1fv37x9uvvnmMGvWrLDuuuuWcUKoDH/729/CdtttFxo2bPhd7Z133gndu3cPhxxySLj11lvLOB1UtqVLl4Ztt902LFy4MLz11lvlHidr/qu3zObMmRNCCKFNmzbfq2+wwQahXr163/tLClh5O++88w+ep0033TR069YtvPnmm2WaCvJQv3790L59+zB79uxyj5I9wa/M9thjjxBCCMcee2x4+eWXw4cffhjGjh0brr766nDyySeHpk2blndAqGDV1dXh008/Da1atSr3KFBx5s2bF7744oswffr0cPnll4fx48eHvfbaq9xjZc9/9dYBF1xwQRg+fHhYsGDBd7UhQ4aECy64oIxTQeW79dZbw5FHHhlGjRoVBgwYUO5xoKKccMIJ4dprrw0hhFCvXr1w0EEHhb/85S++fanMGpR7AELYeOONw2677RYOPvjg0LJly/DAAw+E4cOHh/XXXz8MHjy43ONBRXrrrbfCoEGDwk477RT69+9f7nGg4pxyyinhkEMOCR9//HG44447wtKlS8O3335b7rGy541fmd1+++1hwIABYdq0aaFdu3bf1Y855phwxx13hA8++CC0bNmyjBNC5Zk5c2bYZZddwuLFi8OkSZNC27Ztyz0SVLyePXuG2bNnh+effz5UVVWVe5xs+R6/MrvqqqtCjx49vhf6QgihT58+Yf78+WHq1Kllmgwq09dffx322WefMHv27PDQQw8JfVAihxxySJg8ebKzM8tM8CuzTz/9NCxduvQH9cWLF4cQQliyZEmpR4KKtXDhwtC7d+8wbdq0MG7cuNC1a9dyjwTZ+Nf3sX/99ddlniRvgl+ZbbbZZmHq1Kk/+BfQmDFjQr169cKWW25ZpsmgsixdujQcdthh4bnnngt33nln2Gmnnco9ElSkzz777Ae1xYsXh5tvvjk0btzYP7jKzOaOMjvjjDPC+PHjw6677hoGDx4cWrZsGcaNGxfGjx8ffvnLX/pvKCiS0047Ldx3332hd+/eYdasWT84sPkXv/hFmSaDynL88ceHOXPmhN122y1suOGGYebMmWH06NHhrbfeCn/4wx9Cs2bNyj1i1mzuqANeeOGFMHTo0DB16tTw5Zdfho4dO4b+/fuHM888MzRoIJtDMeyxxx7hySefTK77oxCK4/bbbw+jRo0Kr776avjyyy/DWmutFbbddttw0kknhT59+pR7vOwJfgAAmfA9fgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATgh8AQCZW+HTgqqqq2pwDyqIuHmPpWaMSedagNJb3rHnjBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQiQblHgDg3+23337ReocOHZI9hx12WLS+4YYbJns6deoUrderl/438W233Rat9+nTJ9lz5plnRuu33HJLsmfu3LnJNYCV5Y0fAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGSiqrq6unqFfmBVVW3PUie0aNEiuZbaNdi1a9dkzw477BCtz5o1K9nz7rvvRutHHHFEsie107B79+7JnldffTW5lnLNNddE6//4xz+SPfPmzSv4PqWygl/+JZXLs7bbbrsl1+69995ofa211qqtcb6npt+DYn7N3H333cm1gQMHRus1/dlRl3nWCtO2bdto/bzzzkv2/OpXv4rWV+bredy4ccme119/PVq/5557kj0vvPBCco3iWt6z5o0fAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyES2x7m0bt06Wk8dIxFC+miWUh1TUKojJlZmhpdffjnZc9xxx0XrL774YjFGWiWOmCif/fbbL7lW03NYCnXhWevbt2+0XtORGXWZZ+2HevXqlVz705/+FK137ty5qDMsWrQoWl9zzTWLep/HHnssWh8xYkSy54knnijqDLlwnAsAACEEwQ8AIBuCHwBAJgQ/AIBMCH4AAJnIdlfvxhtvHK3XtIuoQ4cO0XpNv4Tjx4+P1gcMGJDs2WKLLaL1mj7Uvpg75lL3DyG9E7OmHWAffvhhtN6xY8fCBqsFdhqWj129Nfvggw+i9U6dOpXk/sWW87OW+vPxzTffTPa0bds2Wh8zZkyyZ8KECYUNVkNPz549kz2tWrWK1i+44IJkT7NmzaL1xYsXJ3v69esXra+uO9tLxa5eAABCCIIfAEA2BD8AgEwIfgAAmRD8AAAyIfgBAGQi2+NcUjbZZJPk2llnnRWtH3300cmel156KVqv6SiLzz//PLlWbn369InW//u//zvZk/oQ8L322ivZM2nSpMIGW0k5HzFRbo0bN06u3XfffdH6nnvuWfB95syZk1x7+umno/Xu3bsnew4//PBo/ZNPPkn2DBw4MFo/88wzkz2Oc6l9pXrWmjZtGq3X9LV52WWXRetnnHFGUWaqDe3atUuuHXnkkdH673//+2TPe++9F61vv/32yZ6afk1z4TgXAABCCIIfAEA2BD8AgEwIfgAAmRD8AAAy0aDcA9Q106dPT66de+650Xrqw7RDSH/Q9aBBg5I9Q4cOTa6V28MPPxytT5kyJdmz3XbbRes17QCj8i1YsCC5ltpBv9566xV8n2+++Sa59swzz0TrW2yxRbLntddeK3gGOw3zljrZ4KCDDkr2PProo7U1Tq356KOPkmsjRoyI1lO7fUMIYfPNN4/W11lnnWSPZ235vPEDAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmXCcSwFSH8K+7777Jns+/fTTaP3YY49N9lx77bUF3b+UOnfuHK3X9KHZCxcujNbffffdosxE5anpeKBSWJkjW4otdWTF7rvvnux58skna2kaVsWSJUui9XvvvbfEk5RPo0aNovU11lijxJPgjR8AQCYEPwCATAh+AACZEPwAADIh+AEAZMKu3lqW2rn6ox/9KNlz9NFHR+upD7kupU022SRar66uTvYsWLAgWp8xY0ZRZoK6YO+9906uDRkypODr1a9fP1pfa621Cr4WlNt2220XrXfq1CnZ89JLL0Xrn332WVFmypU3fgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATjnOpZZdddlm0Pnbs2GTP2WefHa23b98+2XPiiScWNlgNdthhh+TamDFjCr7er371q2j9888/L/haUFf1798/uda4ceOCr/fll19G6+PGjSv4WlAKVVVVybWTTjopWl+2bFmyJ/X35MKFCwsbjO/xxg8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMmFXbxFsvfXWybXf/va3BV8vtQOwX79+yZ6RI0dG62+88UayZ5111onWL7jggmRPo0aNovW77ror2fPggw8m12B107lz52h9++23L/EkULcccMABybW+fftG65MnT072XHrppas6EhHe+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMOM6lAKmt6jfffHOyp0mTJkW7/9KlS5Nr3377bbS+ww47JHtSx7b85Cc/SfZMnz49Wh8wYECyZ9GiRck1KMSOO+6YXOvRo0e0vsEGGyR7hgwZEq3Xq5f+N3FNHypfTE8//XRJ7gOF2mabbaL1q6++OtlTXV0drY8YMaIoM7HivPEDAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEzY1ftvzjnnnOTasGHDovXUbqUQQrj11lsLulYIIRx99NEFz/bggw9G6xtuuGGyp1GjRtH6U089lezZc889k2sQ0759+2h9o402SvYMHDgwWq9px/l6661X2GAh/ezWtHO3pue9mG6//faS3AcKdeyxx0brNT2DL7/8crT+0EMPFWMkCuCNHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMhEtse5HHLIIdH6mWeemexJHeNw3XXXJXsGDx4crS9evDjZc+6550brhx12WLKnU6dOybWUu+66K1pPfXA9NGgQ/yOjVatWyZ7/9//+X7S+1VZbFWOkijVgwIBo/fHHH0/2LFq0qLbGgVVSv379aH277bYr6n3eeOONaH3WrFlFvc/qzBs/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMhEVfUKfuJ4VVVVbc9SdAceeGBybfTo0dF6w4YNkz2jRo2K1lM7d0Ooefduobbddtvk2vPPP1/w9Q4//PBoPbXbtxKt4Jd/SdXlZ+3HP/5xtD5x4sTSDlLLavo9KPfXzMMPP5xcu+aaa6L1+++/v7bGWWHl/nWLqcvPWl123HHHReuXX355sqdRo0a1Nc73zJgxI1p/4oknkj133HFHtP7AAw8UZaZSW96z5o0fAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyERFHOfSunXraP3NN99M9jRv3jxanzBhQrJn3333LWywIuvWrVty7e9//3vB13OciyMmYjbaaKPk2t133x2tb7311rU0TXnU5eNcajJv3rxofWU+oL5jx46rOs731MVft3I/a5Vmk002Sa716NEjWj/kkEOSPam/p2vSpk2baH2rrbZK9nz44YfR+uabb57sWbRoUWGDlZDjXAAACCEIfgAA2RD8AAAyIfgBAGRC8AMAyESDcg9QDLvvvnu0vjI7gi688MJVHQdWa/fff39yrWvXriWcpG765JNPovW//vWvyZ7JkydH6xdccEGyZ9111y1ssBBCu3btovXUTscQQrj88ssLvg/ETJ8+veC1Yp8i0aRJk2j9kUceSfbstNNO0Xq9epX5bqwyf1YAAPyA4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmaiI41xOPPHEaL2mD+C+5557ovVnn322KDPVhpo+ADv1c73uuuuSPcXeRk9l6NatW3JteR/+XSnOPvvs5Nr1118frX/++ecF32f8+PEF99TklFNOida//vrrZM8NN9xQ1BmgnLbccstofdttt032TJw4MVr/9ttvizFSneONHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkoiJ29aZ2Gta0A3HKlCm1Nc4Kad26dXIttUv53HPPTfakfq7nnHNOYYORvcmTJyfXtttuuxJOUph//OMf0XpNu9eHDx8erc+ZM6cYI5XcH//4x3KPALWuS5cuybW//vWv0XpNp3yMHTs2Wl+6dGlhg60mvPEDAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmaiI41wWLFhQcM95550Xre+9997JniOOOCJa33///ZM9bdu2jdb322+/ZM8222wTrde0tXzIkCHR+pdffpnsgZjLLrssuTZq1KhovXHjxkWdIfXh6G+//Xayp3///tH6K6+8UpSZgH9q0aJFtF7T32u33HJLtN6wYcNkz1VXXRWtp/4uDiGENddcM1qfMGFCsufaa69NrlUib/wAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBNV1dXV1Sv0A2v4gONya9euXbQ+fvz4ZM9//Md/FHyf1K/BCv4SrrDJkydH66mdyCHUvGOJtGL/3hVDXX7WDj300Gg9tXs9hBAuvfTSgu9z0UUXReup3evUfZ61ypE6eWLSpEnJnkcffTRab9SoUbJn9913j9aXLFmS7PnTn/4UrQ8bNizZM3fu3OTa6mh5z5o3fgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATFXGcS0qHDh2Sa2eccUa0fvjhhyd7Uh9MXdMv4Q033BCt33fffcme1NEsixYtSvawchwxAaXhWascTZs2jdZHjx6d7Ondu3fB93n88cej9d///vfJnmeeeabg+1Qax7kAABBCEPwAALIh+AEAZELwAwDIhOAHAJCJit7VC8tjpyGUhmcNSsOuXgAAQgiCHwBANgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATFRVV1dXl3sIAABqnzd+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4JfHfDiiy+GXr16hbXXXjustdZaoWfPnuHll18u91hQcTxrUDovvfRS6NOnT2jRokVo0qRJ2GKLLcIVV1xR7rGyV1VdXV1d7iFy9tJLL4VddtkltG/fPhx//PFh2bJl4aqrrgqzZs0KL7zwQth8883LPSJUBM8alM6ECRNC7969Q48ePcJhhx0WmjVrFqZPnx6WLVsWLr744nKPlzXBr8z222+/8Nxzz4V33nkntGzZMoQQwieffBI222yz0LNnz3D33XeXeUKoDJ41KI05c+aEzTbbLOy8887hrrvuCvXq+c/FusTvRpk9/fTTYe+99/7uL6IQQthggw3C7rvvHsaNGxfmzp1bxumgcnjWoDRuu+228Omnn4YLL7ww1KtXL8ybNy8sW7as3GPxPwS/Mlu0aFFo3LjxD+pNmjQJ3377bXjttdfKMBVUHs8alMajjz4a1l577TBjxoyw+eabh2bNmoW11147DBw4MCxcuLDc42VP8CuzzTffPEyaNCksXbr0u9q3334bnn/++RBCCDNmzCjXaFBRPGtQGu+8805YsmRJ2H///cN//ud/hrvvvjsMGDAgXHPNNeGYY44p93jZE/zK7MQTTwzTpk0Lxx57bHjjjTfCa6+9Fo466qjwySefhBBCWLBgQZknhMrgWYPSmDt3bpg/f3446qijwhVXXBEOOuigcMUVV4Tjjz8+3H777eGdd94p94hZE/zK7IQTTghnn312uO2220K3bt1C9+7dw/Tp08OZZ54ZQgihWbNmZZ4QKoNnDUrjX99S0a9fv+/VjzjiiBBCCM8991zJZ+J/CX51wIUXXhg+/fTT8PTTT4dXXnklTJ48+btvhN1ss83KPB1UDs8a1L62bduGEEJo06bN9+qtW7cOIYTw1VdflXwm/pfgV0esu+664cc//nHo3r17COGf3xzbrl270KVLlzJPBpXFswa1a9tttw0h/PD7Zj/++OMQQgjrrbdeyWfifwl+ddDYsWPD5MmTwymnnOL8I6hFnjUovkMPPTSEEMKoUaO+V7/uuutCgwYNwh577FGGqfiXBuUeIHdPPfVUGDZsWOjZs2do2bJlmDRpUrjhhhtCr169wq9//etyjwcVw7MGpdGjR48wYMCAcP3114clS5aE3XffPUycODHceeed4ayzzvruv4IpD5/cUWbTp08PJ554YnjppZfCN998Ezp27Bj69+8fTj311NCwYcNyjwcVw7MGpbN48eIwfPjwcMMNN4SPP/44bLTRRmHQoEHhlFNOKfdo2RP8AAAy4ZtaAAAyIfgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATKzwJ3dUVVXV5hxQFnXxGEvPGpXIswalsbxnzRs/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATDQo9wAAACuqX79+ybWLLrooWj/mmGOSPY899tgqz7Q68cYPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZKKqurq6eoV+YFVVbc8CJbeCX/4l5VmjEnnWKNSRRx4ZrV9//fXJnvr160frDz/8cLJnn332KWywOm55z5o3fgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQiQblHgAAyFOfPn2Sa9ddd1203qBBOrq8+uqr0foNN9xQ2GAVzBs/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkImq6hX85GwfZl1+Xbp0Sa4NGTIkWv/5z3+e7En9ni5cuDDZc8ABB0TrNX0Adl3mg+NXL02bNk2uvfvuu9F669atkz316sX/7bts2bJkzwMPPBCtDx06NNnz0ksvJddy4VnLW5s2baL1p59+OtnTuXPnaH3OnDnJnl69ekXrkyZNqmG6yrK8Z80bPwCATAh+AACZEPwAADIh+AEAZELwAwDIRPqTjqlVXbt2Ta6dc8450fqhhx6a7EntTnzyySeTPe+88060/stf/jLZs//++0frq+uuXspnzTXXTK6dfvrp0fqpp56a7GnevHm0PnPmzGTP3/72t2h9l112Sfbsu+++0Xrbtm2TPdttt11yDSpFw4YNk2sjRoyI1lM7d0MIYcGCBdH6+eefn+zJaffuyvLGDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGTCcS617De/+U20fu655yZ76tevH61fdtllyZ7U2meffZbsSR3NUtNxLlAsl156aXJt4MCB0fr777+f7HnwwQej9QEDBiR7Fi9eHK03adIk2XPjjTdG61OmTEn2QA6uvfba5Fr//v2j9erq6mTP2WefHa3/6U9/KmwwvscbPwCATAh+AACZEPwAADIh+AEAZELwAwDIRFV1TVtq/u8PrKqq7VlWW7///e+Ta0OGDInWX3zxxWTPoEGDovVi7xocPXp0tH7wwQcne1IfXl/Tz6cuW8Ev/5KqtGetWbNm0frEiROTPakPZ99nn32SPXPnzi1orrqgpj87Ul+bqQ+7DyGERYsWrfJMtcWzVjkOOOCAaH3s2LHJnjXWWCNav/DCC5M9NZ1+QdrynjVv/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmHOdSgMMPPzxa/+tf/5rseeONN6L1/fbbL9nzxRdfFDZYDbbddtvk2nPPPRetjxo1KtkzcODAVZ6pLnHERHGkjmwJIYSrr746Wu/Vq1ey5+c//3m0PmHChMIGqyOGDRsWrdf0PC1dujRar+mZnjFjRmGDlZBnrXJMmzYtWu/cuXOyJ/X35AknnJDsqYtfM6sDx7kAABBCEPwAALIh+AEAZELwAwDIhOAHAJCJBuUeYHUyaNCgaD21+y6EEPr27RutF3PnbgghdOnSJVr/4x//mOxp0CD+23/XXXcVYyQyMnTo0ORav379ovXx48cne1bX3bspqZ246667brLnoosuitbr8s5dKsf555+fXKtp927K5MmTo3U7d0vPGz8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCce5/Juatqlvs8020foFF1yQ7Pnggw9WeaZ/qWl7/cknnxytr7XWWsmeJ598Mlp/6623ChuM7LVv377gnuuvv74WJimfAw44ILm28847R+vPPvtssqemP1egWOrVi7//SX3N1qSmZ/rGG28s+HrUDm/8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATdvX+m3XWWSe51qBB/JfrmGOOSfbU9CHsKVtssUW0vtdeeyV71lhjjWj9gQceSPYcddRR0fpXX31Vw3TkrEWLFtF6ly5dCr7WQQcdlFy75557Cr5eMe24447Jte7du0frgwcPTvakdtdfcsklyZ4FCxYk16BYWrZsGa3vueeeBV+rpp3oS5YsKfh61A5v/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmHOfyb6ZMmZJcGzNmTLTer1+/ZM/pp59e8Ayp41RSR7aEEMKiRYui9Zo+GNuxLRRq1qxZ0fro0aOTPcOHD4/WazrOpW3bttH6wQcfnOxJrTVp0iTZc9ZZZ0XrqQ+uDyGEIUOGROudOnVK9jz//PPR+oQJE5I9UAqnnXZawT2pr+ea/k5JHQW1++67J3vef//9aH3atGnJnrlz5ybX+Cdv/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE1XV1dXVK/QDq6pqe5bV1iabbJJca9Cg8I3TP/nJT6L1K6+8Mtlz7733RusHHnhgwffPyQp++ZfU6vis1a9fP7n2wAMPROt77713wfdZsGBBcq1Ro0bRek2/nueff360fskllyR7+vbtG62PGjUq2XPxxRdH62effXayp9J41uqmRx99NFpP/T0UQgivvvpqtF7TDvqa/p4s1IwZM5JrRx11VLT+xBNPFO3+dd3ynjVv/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmCj9rhB+YPn16wT01fdj80KFDC75e6kOzoRSWLl2aXOvVq1e0XtPxDoceeugqz/Qvf/jDH5Jr3377bbS+0UYbJXuuv/76aH3ZsmXJnpyOkqDyde/evWjXevzxx5NrrVq1ita33HLLZM/w4cOj9R//+MfJnpr+/KpE3vgBAGRC8AMAyITgBwCQCcEPACATgh8AQCbs6i2TbbbZJrm23nrrResPPfRQsuemm25a5ZmglGraDT9ixIgSTvJDp556anIt9QHozz77bLLnkUceWeWZYGW1bt06ubbHHnsU7T6jR49Orv3xj3+M1qdOnZrsWXPNNaP1Z555Jtnzox/9KFr/6U9/muyp6e/WSuSNHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE41zKpEuXLgX3nHHGGcm1Tz75ZFXGgSzVqxf/t2/z5s0LvtbIkSNXdRyoFVVVVcm11DNQk7PPPjtav+KKK5I98+fPL/g+v/71r6P1Hj16JHvGjx8frT/88MMF379SeeMHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJmoqk594vi//8AadgWRtv/++0frY8aMSfZMnDgxWj/kkEOSPSuzY4oQVvDLv6Q8a6XTuXPnaP2tt95K9qR20O+0007Jno8++qiwwSqQZ618mjZtmlx75ZVXovWOHTsmexo2bBitL1myJNnTunXraP2EE05I9px11lnR+qRJk5I9/fr1i9ZnzpyZ7Kk0y3vWvPEDAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmWhQ7gEqwRprrJFcGzBgQLTeqFGjZE/qOBdHtkBxnXvuuQX3zJs3L1p3ZAt1VeprNoQQ3nvvvWi9puNcTjvttGi9RYsWyZ7+/ftH66ljXkII4fnnn4/WU8ekhRDCnDlzkmv8kzd+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJu3qL4PTTT0+u9e7dO1p/+OGHkz0jR45c5ZmA5fvFL34Rrdf0Iee33nprbY0DJXfNNddE67vttluyZ8SIEQXfZ9myZdH6Y489luwZOHBgtG7n7qrxxg8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkoqq6pnML/u8PrKqq7VnqvPXXXz9af+KJJ5I9nTt3jtZ33XXXZM+kSZMKG4yVtoJf/iXlWSudpUuXRuuff/55sqdr167R+qxZs4oyU6XyrK1efvOb3yTXTjrppGj9iy++SPbccMMN0frVV19d2GAs1/KeNW/8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATDco9wOrkuOOOi9Y333zzZM8ll1wSrdu5C6WR+qD3mlx55ZXJNbt3ycHll1++UmvUfd74AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEw4zuXf9O7dO7l21llnResTJkxI9gwdOnRVRwJWwTrrrFNwz1dffVX8QQDqAG/8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATVdXV1dUr9AOrqmp7ljrh6quvTq4df/zx0foOO+yQ7JkyZcoqz0TtWcEv/5LK5VkrlYYNGybX5syZE63vscceyZ5Jkyat6khZ8qxBaSzvWfPGDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGTCcS5kzRETUBqeNSgNx7kAABBCEPwAALIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMhEVXVd/ORsAACKzhs/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEz8fzXv1KlMYrEaAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um8QcBw-qE3a"
      },
      "source": [
        "Przy projektowaniu sieci neuronowych możemy wyróżnić podstawowe operacje (warstwy), które się powtarzają. Dla wygody, PyTorch zawiera gotowe implementacje najprostszych z nich, oraz udostępnia interfejsy do tworzenia własnych, bardziej skomplikowanych.\n",
        "\n",
        "Operacje możemy podzielić na:\n",
        "* **uczalne** - zawierające zmienne uczalne (np. *w* i *b* w warstwie w pełni połączonej),\n",
        "* **nieuczalne** - takie, które wykonują pewne charakterystyczne działania na danych, jednak nie potrzebują do tego zmiennych, które będą uczone w trakcie propagacji gradientu.\n",
        "\n",
        "Poniżej zaprezentowane zostały popularne operacje uczalne i nieuczalne.\n",
        "\n",
        "**Uwaga**\n",
        "Wszystkie operacje są reprezentowane jako klasy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4PMPG23oKgP"
      },
      "source": [
        "## Podstawowe warstwy neuronowe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi5VgRQ7peBQ"
      },
      "source": [
        "### Uczalne\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnh4-j1XtP8k"
      },
      "source": [
        "Dzięki predefiniowanym warstwom nie ma potrzeby samodzielnej deklaracji nowych zmiennych. Wszystkie zmienne uczone są deklarowane (zgodnie z implementacją danej warstwy) wewnątrz obiektu, a następnie przechowywane.\n",
        "\n",
        "Do zmiennych uczonych można dostać się poprzez własność *state_dict* (lub *parameters*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FI5eoguKtxCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ccbfffc-9ebb-4519-ae2a-a4c25d422a17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[-0.0392,  0.3315, -0.3711, -0.2124,  0.1394],\n",
              "                      [ 0.4319, -0.1261, -0.3279,  0.1321, -0.2011],\n",
              "                      [-0.3741,  0.3075, -0.4426,  0.2011,  0.3147],\n",
              "                      [-0.3319, -0.4240, -0.2771,  0.0536, -0.2845],\n",
              "                      [-0.2033, -0.2596,  0.1179, -0.3716, -0.3345]])),\n",
              "             ('bias', tensor([-0.2858,  0.0152,  0.3556,  0.0363, -0.1457]))])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "m = torch.nn.Linear(5, 5)\n",
        "\n",
        "m.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfk3PAOvpjcK"
      },
      "source": [
        "#### Linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSE1DNZErodm"
      },
      "source": [
        "Jest to warstwa w pełni połączona, która pobiera jako wejście wektor i produkuje na wyjściu wektor o długości równej rozmiarowi warstwy (liczby neuronów)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ylb4JpMAr2DQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd5e4b1-8ad0-45b7-c885-ba1e9781b055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8]) torch.Size([2])\n",
            "Wagi w warstwie linear: tensor([[-0.1980, -0.3147,  0.0993, -0.0121,  0.1321, -0.1977,  0.1530, -0.1874],\n",
            "        [ 0.1788,  0.1308, -0.1860,  0.0620,  0.1745, -0.2975,  0.1633,  0.1409]])\n",
            "Bias'y w warstwie linear: tensor([-0.1167,  0.3248])\n"
          ]
        }
      ],
      "source": [
        "# definicja warstwy\n",
        "linear1 = torch.nn.Linear(8, 2)\n",
        "\n",
        "# inferencja\n",
        "x = torch.ones([8])\n",
        "y = linear1(x)\n",
        "\n",
        "# rozmiar wejściowego oraz wyjściowego tensora\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "# zmienne uczone\n",
        "state_dict = linear1.state_dict()\n",
        "print(f\"Wagi w warstwie linear: {state_dict['weight']}\")\n",
        "print(f\"Bias'y w warstwie linear: {state_dict['bias']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEzIeQLKplLd"
      },
      "source": [
        "#### Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKyyxUqvuejZ"
      },
      "source": [
        "Warstwa w pełni połączona dobrze sprawdza się przy danych jednowymiarowych. W przypadku danych wielowymiarowych (jak obrazy) korzystanie z nich byłoby bardzo kosztowne obliczeniowo. Aby wykonać pojedynczą operację *Linear* z 128 neuronami na obrazie o rozmiarach (256, 256, 3) należałoby zadeklarować  256 * 256 * 3 * 128 = 25165824 zmiennych uczonych.\n",
        "\n",
        "Popularnym rozwiązaniem efektywnego przetwarzania danych wielowymiarowych są operacje konwolucji ([link do wizualizacji](https://github.com/vdumoulin/conv_arithmetic)). Konwolucja (inaczej splot) w sieciach neuronowych intuicyjnie jest, tak samo jak *Linear*, kombinacją liniową danego podobszaru danych wielowymiarowych i zmiennych uczonych (inaczej *kernel*).\n",
        "\n",
        "Konwolucja w PyTorch posiada szereg parametrów takich jak:\n",
        "* liczba kanałów wejściowych - liczba kanałów w obrazie wejściowym,\n",
        "* liczba kanałów wyjściowych - liczba kanałów \"wyprodukowana\" przez konwolucję,\n",
        "* kernel_size - rozmiar kernela,\n",
        "* stride - \"rozstrzał\" przetwarzanego podobszaru (patrz link do github),\n",
        "* padding - dopełnienie dodane do wszystkich czterech stron danych wejściowych. Domyślnie: 0,\n",
        "\n",
        "W porównaniu do przykładu przytoczonego powyżej, konwolucja z 128 filtrami, rozmiarem kernela równym (3, 3), dla takich samych danych wejściowych zawierałaby 3 * 3 * 3 * 128 = 3456, czyli ponad 7281 (!) razy mniej niż w przypadku *Linear*. Ponadto, w przetwarzaniu danych, w których zachodzą lokalne zależności (na obrazie sąsiadujące piksele reprezentują zazwyczaj ten sam obiekt) konwolucja sprawdza się o wiele lepiej niż *Linear*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MGMUqvtcwFQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf10c44c-26b1-473f-8d37-6005764d4812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 128, 128, 3]) torch.Size([10, 128, 64, 2])\n",
            "Wagi w warstwie conv: torch.Size([128, 128, 3, 3])\n",
            "Bias'y w warstwie conv: torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "# definicja warstwy\n",
        "conv1 = torch.nn.Conv2d(128, 128, (3, 3), (2, 2), 1)\n",
        "\n",
        "# inferencja (przy pierwszym wywołaniu warstwy Linear1 zostaną stworzone zmienne uczone)\n",
        "x = torch.ones([10, 128, 128, 3])\n",
        "y = conv1(x)\n",
        "\n",
        "# rozmiar wejściowego oraz wyjściowego tensora\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "# zmienne uczone\n",
        "state_dict = conv1.state_dict()\n",
        "print(f\"Wagi w warstwie conv: {state_dict['weight'].shape}\")\n",
        "print(f\"Bias'y w warstwie conv: {state_dict['bias'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3fPzepapfuY"
      },
      "source": [
        "### Nieuczalne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMV7LJQeRuXG"
      },
      "source": [
        "Warstwy nieuczalne zazwyczaj wykonują pewne operacje techniczne, typu zmiana kształtu, skalowanie danych, lub są wykorzystywane w **regularyzacji** (o czym będzie mowa na kolejnych zajęciach)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIl-axl0pu0s"
      },
      "source": [
        "#### Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoDcI-1sRtFq"
      },
      "source": [
        "Jest to jedna z popularniejszych metod regularyzacji, polegająca na wykonaniu pewnej operacji na małym wycinku danych. Przykładowo MaxPooling2D, podobnie jak konwolucja 2D (patrz wizualizacje), wybiera podobszar obrazu o jakichs wymiarach (np. 2x2) a następnie wybiera maksymalny obiekt z tego okna, tworząc nowy obraz (np. zmniejszony 2-krotnie). Istnieją również inne metody poolingu:\n",
        "\n",
        "* average - z okna obliczana jest średnia,\n",
        "* median - z okna obliczana jest mediana,\n",
        "* minimum - z okna wybierana jest najmniejsza wartość,\n",
        "* itp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EmJStBb_zTO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d575b3a-f9d9-4a22-9337-01517dc5098c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 128, 128, 3]) torch.Size([10, 128, 64, 1])\n"
          ]
        }
      ],
      "source": [
        "# definicja warstwy\n",
        "mp1 = torch.nn.MaxPool2d((2, 2), (2, 2))\n",
        "\n",
        "# inferencja (przy pierwszym wywołaniu warstwy Linear1 zostaną stworzone zmienne uczone)\n",
        "x = torch.ones([10, 128, 128, 3])\n",
        "y = mp1(x)\n",
        "\n",
        "# rozmiar wejściowego oraz wyjściowego tensora\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2C6kjTBpw3w"
      },
      "source": [
        "#### Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2_3pL2QSz4M"
      },
      "source": [
        "Flatten jest prostą funkcją spłaszczającą **każdy element w batchu**. Przykładowo dla grupy 10 obrazów o pewnych wymiarach wyprodukowanych zostanie 10 wektorów (spłaszczonych do wektorów obrazów)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x5rs9OqBzoCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448fce2c-9e67-44d9-f297-f5023825f1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 128, 128, 3]) torch.Size([10, 49152])\n"
          ]
        }
      ],
      "source": [
        "# definicja warstwy\n",
        "ft1 = torch.nn.Flatten()\n",
        "\n",
        "# inferencja (przy pierwszym wywołaniu warstwy Linear1 zostaną stworzone zmienne uczone)\n",
        "x = torch.ones([10, 128, 128, 3])\n",
        "y = ft1(x)\n",
        "\n",
        "# rozmiar wejściowego oraz wyjściowego tensora\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMqJe-T1oY-9"
      },
      "source": [
        "## Proces uczenia sieci neuronowej"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EorLINSXTTcE"
      },
      "source": [
        "Proces uczenia sieci neuronowych składa się z kilku części. Po inicjalizacji modelu oraz zbioru danych następuje uczenie modelu składające się z wielu **epok**. Epoka to pojedyncze przeiterowanie po całym zbiorze danych (podzbiory treningowe i walidacyjne). Przy czym model jest uczony (bład jest propagowany) tylko na zbiorze treningowym. **Nigdy na zbiorach walidacyjnym i testowym.** Proces uczenia sieci neuronowej składa się (najczęściej) następujących części:\n",
        "\n",
        "1. Inicjalizacja modelu,\n",
        "2. Inicjalizacja zbioru danych,\n",
        "3. Pętla treningowa,\n",
        "  1. Uczenie na zbiorze treningowym (raz!),\n",
        "  2. Ocena modelu na zbiorze walidacyjnym,\n",
        "4. Ocena modelu na zbiorze testowym (opcjonalne)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qro02c56Uskh"
      },
      "source": [
        "#### Inicjalizacja modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgzk0y0GU3Ty"
      },
      "source": [
        "**Uwaga:** Jeśli model składa się z następujących po sobie operacji, można opakować go dla wygody w strukturę *Sequential*, tak jak pokazano poniżej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bZWoSMEeHhhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578aa304-2625-41e9-b610-dcc6eb8b741f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "_IxiftCDUuVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566fb470-2670-4d02-cda0-c3d5c78c2e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (conv_relu_stack): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 32, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(32, 16, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=10, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn.modules.activation import ReLU\n",
        "\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Model który na wejściu otrzymuje obraz a na wyjściu produkuje skalar\n",
        "\n",
        "        W skład modelu wchodzą 3 warstwy konwolucyjne o rozmiarach 64, 32, 16 (out_channels),\n",
        "        każda z rozmiarem kernela 5x5 oraz stride 2x2 (czyli obraz po każdej warstwie będzie 2 razy mniejszy)\n",
        "        potem następuje spłaszczenie obrazu do wektora i przetwarzanie warstwami w pełni połączonymi.\n",
        "        Wszystkie warstwy (oprócz wyjściowej) korzystają z funkcji aktywacji 'relu'\n",
        "        \"\"\"\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv_relu_stack = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=5, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(in_features=64, out_features=32),\n",
        "            ReLU(),\n",
        "            nn.Linear(in_features=32, out_features=10),\n",
        "            ReLU(),\n",
        "            nn.Linear(in_features=10, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.conv_relu_stack(x)\n",
        "        x = self.flatten(x)\n",
        "        return self.linear_relu_stack(x)\n",
        "\n",
        "\n",
        "model = MyModel()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBfKk6KSWWXF"
      },
      "source": [
        "#### Inicjalizacja zbioru danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z242L-5DWZBc"
      },
      "source": [
        "Jako zbiór danych wykorzystany zostanie zaprezentowany wcześniej zbiór **MNIST**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "RZQ0CdUiWnbZ"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "mUyzOt0OWYeX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBmDlmOAf3b7"
      },
      "source": [
        "### Proces uczenia sieci neuronowej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "dUDPmj0bHhhG"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 32\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "mmE-IwkOZMUY"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "-4kmh8WItrUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00dcb2a3-e03d-48a4-9404-d0e973fc84ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.315616  [   32/60000]\n",
            "loss: 1.063976  [ 3232/60000]\n",
            "loss: 0.930766  [ 6432/60000]\n",
            "loss: 1.059689  [ 9632/60000]\n",
            "loss: 0.350513  [12832/60000]\n",
            "loss: 0.411303  [16032/60000]\n",
            "loss: 0.201484  [19232/60000]\n",
            "loss: 0.496849  [22432/60000]\n",
            "loss: 0.204275  [25632/60000]\n",
            "loss: 0.176738  [28832/60000]\n",
            "loss: 0.093858  [32032/60000]\n",
            "loss: 0.315600  [35232/60000]\n",
            "loss: 0.242938  [38432/60000]\n",
            "loss: 0.142801  [41632/60000]\n",
            "loss: 0.214895  [44832/60000]\n",
            "loss: 0.209402  [48032/60000]\n",
            "loss: 0.445284  [51232/60000]\n",
            "loss: 0.111880  [54432/60000]\n",
            "loss: 0.213967  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118716 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.044347  [   32/60000]\n",
            "loss: 0.053014  [ 3232/60000]\n",
            "loss: 0.135591  [ 6432/60000]\n",
            "loss: 0.194220  [ 9632/60000]\n",
            "loss: 0.045715  [12832/60000]\n",
            "loss: 0.428774  [16032/60000]\n",
            "loss: 0.144221  [19232/60000]\n",
            "loss: 0.135690  [22432/60000]\n",
            "loss: 0.277268  [25632/60000]\n",
            "loss: 0.043741  [28832/60000]\n",
            "loss: 0.008845  [32032/60000]\n",
            "loss: 0.048016  [35232/60000]\n",
            "loss: 0.026699  [38432/60000]\n",
            "loss: 0.006489  [41632/60000]\n",
            "loss: 0.122290  [44832/60000]\n",
            "loss: 0.037949  [48032/60000]\n",
            "loss: 0.079535  [51232/60000]\n",
            "loss: 0.046397  [54432/60000]\n",
            "loss: 0.018973  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.065208 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.115535  [   32/60000]\n",
            "loss: 0.324173  [ 3232/60000]\n",
            "loss: 0.005396  [ 6432/60000]\n",
            "loss: 0.044765  [ 9632/60000]\n",
            "loss: 0.137307  [12832/60000]\n",
            "loss: 0.003717  [16032/60000]\n",
            "loss: 0.005384  [19232/60000]\n",
            "loss: 0.082345  [22432/60000]\n",
            "loss: 0.021305  [25632/60000]\n",
            "loss: 0.022396  [28832/60000]\n",
            "loss: 0.011879  [32032/60000]\n",
            "loss: 0.014493  [35232/60000]\n",
            "loss: 0.036998  [38432/60000]\n",
            "loss: 0.011938  [41632/60000]\n",
            "loss: 0.096449  [44832/60000]\n",
            "loss: 0.002834  [48032/60000]\n",
            "loss: 0.038911  [51232/60000]\n",
            "loss: 0.038518  [54432/60000]\n",
            "loss: 0.090735  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.3%, Avg loss: 0.057701 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 3\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2s7Isp4633N"
      },
      "source": [
        "#### Zadanie 1\n",
        "\n",
        "Stwórz zbiór danych (bez podziału na zbiory treningowe, walidacyjne i treningowe) składający się z 10000 elementów, zawierający pary (x, y) danych\n",
        "dla funkcji **sinus**. Dane x niech będą z zakresu [-2 * PI, 2 * PI], y - odpowiadające im wartości funkcji sinus.\n",
        "\n",
        "Następnie utwórz providera za pomocą PyTorch Dataset API, który będzie:\n",
        "\n",
        "* tasował dane\n",
        "* mapował tak, aby dane x, z zakresu [-2 \\* PI, 0), były transformowane do przedziału [0, 2 \\* PI)\n",
        "\n",
        "Podpowiedź: (x + 2PI) % 2PI,\n",
        "* grupował dane w batche o rozmiarze 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "_1hnkzMEA7l_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "dataset_size = 10000\n",
        "\n",
        "x = np.linspace(-2 * np.pi, 2 * np.pi, dataset_size)\n",
        "y = np.sin(x)\n",
        "\n",
        "tensor_x = torch.tensor(x, dtype=torch.float32)\n",
        "tensor_y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def transform_sinus(x, y):\n",
        "  x = (x + 2 * np.pi) % 2 * np.pi\n",
        "  return x, y\n",
        "\n",
        "dataset = torch.utils.data.TensorDataset(tensor_x, tensor_y)\n",
        "mappedDataset = MappedDataset(dataset, transform_sinus)\n",
        "dataloader = torch.utils.data.DataLoader(mappedDataset, shuffle=True, batch_size=32)\n",
        "\n",
        "# for x, y in dataloader:\n",
        "#   print(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM_SpGu7ejES"
      },
      "source": [
        "#### Zadanie 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMB9DnMVeppt"
      },
      "source": [
        "Stwórz sieć neuronową składającą się z:\n",
        "\n",
        "* 3 warstw konwolucyjnych (kernel size = 5, liczba filtrów = 128, 64, 32, **bez stride (stride=1)**, aktywacja = relu, **padding='1'**)\n",
        "* 3 warstw Max Pooling-u, każda znajdująca się za kolejną warstwą konwolucyjną (kernel size = 2, **stride = 2**, padding=1, funkcja aktywacji: relu) (tzn. Conv2d -> MaxPool2d -> Conv2d -> MaxPool2d -> ...),\n",
        "* 3 warstw w pełni połączonych (rozmiary: 512, 128, **liczba klas**, funkcja aktywacji: relu)\n",
        "\n",
        "Przetestuj swoją sieć na następujących zbiorach danych:\n",
        "\n",
        "* Cifar 10\n",
        "* Cifar 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "GbK4okcB0Dqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d5b307-9c92-4c07-956d-bc5eb136b385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.conv_relu_stack = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=128, kernel_size=5, stride=1, padding=2),\n",
        "            ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
        "            ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
        "            ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "        )\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            torch.nn.Linear(in_features=32*5*5, out_features=512),\n",
        "            ReLU(),\n",
        "\n",
        "            torch.nn.Linear(in_features=512, out_features=128),\n",
        "            ReLU(),\n",
        "\n",
        "            torch.nn.Linear(in_features=128, out_features=num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.conv_relu_stack(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = NeuralNetwork(10)\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "1W1ZAdDjLh0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6e555e-fb0d-4511-bcf0-e29e6f373ee7"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (conv_relu_stack): Sequential(\n",
            "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (7): ReLU()\n",
            "    (8): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (9): ReLU()\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (11): ReLU()\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=800, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "model = NeuralNetwork(10)\n",
        "\n",
        "# DONE - init dataset\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "F0BX6tH9Nua_"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# DONE - init dataloaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "wjiYpQJYOH5V"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - train networks\n",
        "learning_rate = 1e-3\n",
        "epochs = 5\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "TfYLcHWsPYZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1ecb9b-b6fb-422e-a18c-4b13eac25dea"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.297431  [   32/50000]\n",
            "loss: 1.961807  [ 3232/50000]\n",
            "loss: 1.906437  [ 6432/50000]\n",
            "loss: 1.993695  [ 9632/50000]\n",
            "loss: 1.990707  [12832/50000]\n",
            "loss: 1.463743  [16032/50000]\n",
            "loss: 1.478565  [19232/50000]\n",
            "loss: 1.478493  [22432/50000]\n",
            "loss: 1.237658  [25632/50000]\n",
            "loss: 1.524460  [28832/50000]\n",
            "loss: 1.614998  [32032/50000]\n",
            "loss: 1.168687  [35232/50000]\n",
            "loss: 1.376714  [38432/50000]\n",
            "loss: 1.375384  [41632/50000]\n",
            "loss: 1.764998  [44832/50000]\n",
            "loss: 1.185607  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 1.274821 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.192428  [   32/50000]\n",
            "loss: 1.179512  [ 3232/50000]\n",
            "loss: 1.002019  [ 6432/50000]\n",
            "loss: 1.469337  [ 9632/50000]\n",
            "loss: 1.093521  [12832/50000]\n",
            "loss: 0.933654  [16032/50000]\n",
            "loss: 1.346963  [19232/50000]\n",
            "loss: 1.308478  [22432/50000]\n",
            "loss: 1.130149  [25632/50000]\n",
            "loss: 0.883633  [28832/50000]\n",
            "loss: 1.120854  [32032/50000]\n",
            "loss: 1.359735  [35232/50000]\n",
            "loss: 0.980552  [38432/50000]\n",
            "loss: 1.058038  [41632/50000]\n",
            "loss: 1.257249  [44832/50000]\n",
            "loss: 1.054359  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.8%, Avg loss: 1.154082 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.286436  [   32/50000]\n",
            "loss: 0.965773  [ 3232/50000]\n",
            "loss: 1.019459  [ 6432/50000]\n",
            "loss: 0.910522  [ 9632/50000]\n",
            "loss: 0.899351  [12832/50000]\n",
            "loss: 1.114502  [16032/50000]\n",
            "loss: 1.252376  [19232/50000]\n",
            "loss: 0.802437  [22432/50000]\n",
            "loss: 1.141358  [25632/50000]\n",
            "loss: 0.905851  [28832/50000]\n",
            "loss: 0.876144  [32032/50000]\n",
            "loss: 0.999540  [35232/50000]\n",
            "loss: 1.058295  [38432/50000]\n",
            "loss: 0.890038  [41632/50000]\n",
            "loss: 1.072885  [44832/50000]\n",
            "loss: 0.785445  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 65.2%, Avg loss: 1.009109 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.318740  [   32/50000]\n",
            "loss: 0.969940  [ 3232/50000]\n",
            "loss: 0.990688  [ 6432/50000]\n",
            "loss: 0.988690  [ 9632/50000]\n",
            "loss: 0.746459  [12832/50000]\n",
            "loss: 0.747666  [16032/50000]\n",
            "loss: 0.929813  [19232/50000]\n",
            "loss: 0.763709  [22432/50000]\n",
            "loss: 1.063943  [25632/50000]\n",
            "loss: 1.120004  [28832/50000]\n",
            "loss: 1.278575  [32032/50000]\n",
            "loss: 0.871088  [35232/50000]\n",
            "loss: 0.998760  [38432/50000]\n",
            "loss: 0.807825  [41632/50000]\n",
            "loss: 1.259363  [44832/50000]\n",
            "loss: 0.751764  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 65.6%, Avg loss: 1.025800 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.676772  [   32/50000]\n",
            "loss: 1.112592  [ 3232/50000]\n",
            "loss: 0.810716  [ 6432/50000]\n",
            "loss: 0.582168  [ 9632/50000]\n",
            "loss: 0.993284  [12832/50000]\n",
            "loss: 0.784308  [16032/50000]\n",
            "loss: 0.768074  [19232/50000]\n",
            "loss: 0.981658  [22432/50000]\n",
            "loss: 0.569063  [25632/50000]\n",
            "loss: 0.644911  [28832/50000]\n",
            "loss: 0.594667  [32032/50000]\n",
            "loss: 0.632414  [35232/50000]\n",
            "loss: 0.589164  [38432/50000]\n",
            "loss: 0.879902  [41632/50000]\n",
            "loss: 1.070854  [44832/50000]\n",
            "loss: 0.503240  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 68.4%, Avg loss: 0.912261 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(100)\n",
        "\n",
        "training_data = datasets.CIFAR100(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR100(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zQr3Ie0h66-",
        "outputId": "8e9d11e1-5469-4bff-bd83-6e42caba435e"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 4.600184  [   32/50000]\n",
            "loss: 4.606565  [ 3232/50000]\n",
            "loss: 4.601277  [ 6432/50000]\n",
            "loss: 4.441255  [ 9632/50000]\n",
            "loss: 4.505960  [12832/50000]\n",
            "loss: 4.263085  [16032/50000]\n",
            "loss: 4.299911  [19232/50000]\n",
            "loss: 4.425410  [22432/50000]\n",
            "loss: 4.178503  [25632/50000]\n",
            "loss: 4.266966  [28832/50000]\n",
            "loss: 4.052618  [32032/50000]\n",
            "loss: 3.630601  [35232/50000]\n",
            "loss: 4.560429  [38432/50000]\n",
            "loss: 4.010098  [41632/50000]\n",
            "loss: 4.108679  [44832/50000]\n",
            "loss: 3.927967  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 9.1%, Avg loss: 3.896235 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 3.637828  [   32/50000]\n",
            "loss: 3.663473  [ 3232/50000]\n",
            "loss: 3.830843  [ 6432/50000]\n",
            "loss: 3.787503  [ 9632/50000]\n",
            "loss: 4.036543  [12832/50000]\n",
            "loss: 3.808629  [16032/50000]\n",
            "loss: 3.495084  [19232/50000]\n",
            "loss: 3.475884  [22432/50000]\n",
            "loss: 3.242941  [25632/50000]\n",
            "loss: 4.048459  [28832/50000]\n",
            "loss: 3.770393  [32032/50000]\n",
            "loss: 3.567184  [35232/50000]\n",
            "loss: 3.436841  [38432/50000]\n",
            "loss: 3.432719  [41632/50000]\n",
            "loss: 3.168482  [44832/50000]\n",
            "loss: 3.718345  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 16.7%, Avg loss: 3.512660 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 3.503551  [   32/50000]\n",
            "loss: 3.510447  [ 3232/50000]\n",
            "loss: 3.260455  [ 6432/50000]\n",
            "loss: 3.153959  [ 9632/50000]\n",
            "loss: 2.972307  [12832/50000]\n",
            "loss: 3.634756  [16032/50000]\n",
            "loss: 2.780367  [19232/50000]\n",
            "loss: 3.137257  [22432/50000]\n",
            "loss: 3.147531  [25632/50000]\n",
            "loss: 3.120852  [28832/50000]\n",
            "loss: 3.207418  [32032/50000]\n",
            "loss: 2.970061  [35232/50000]\n",
            "loss: 2.928961  [38432/50000]\n",
            "loss: 3.041061  [41632/50000]\n",
            "loss: 3.324347  [44832/50000]\n",
            "loss: 2.842317  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 19.9%, Avg loss: 3.326596 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.999873  [   32/50000]\n",
            "loss: 3.427166  [ 3232/50000]\n",
            "loss: 3.321516  [ 6432/50000]\n",
            "loss: 2.718248  [ 9632/50000]\n",
            "loss: 3.140087  [12832/50000]\n",
            "loss: 2.908487  [16032/50000]\n",
            "loss: 2.911454  [19232/50000]\n",
            "loss: 3.637063  [22432/50000]\n",
            "loss: 2.855319  [25632/50000]\n",
            "loss: 2.914306  [28832/50000]\n",
            "loss: 3.251045  [32032/50000]\n",
            "loss: 3.430772  [35232/50000]\n",
            "loss: 3.120940  [38432/50000]\n",
            "loss: 3.193082  [41632/50000]\n",
            "loss: 3.087482  [44832/50000]\n",
            "loss: 3.396185  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 23.0%, Avg loss: 3.155319 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.873818  [   32/50000]\n",
            "loss: 2.781694  [ 3232/50000]\n",
            "loss: 2.660963  [ 6432/50000]\n",
            "loss: 3.146849  [ 9632/50000]\n",
            "loss: 2.839468  [12832/50000]\n",
            "loss: 3.055689  [16032/50000]\n",
            "loss: 3.200474  [19232/50000]\n",
            "loss: 2.539616  [22432/50000]\n",
            "loss: 2.715730  [25632/50000]\n",
            "loss: 3.229199  [28832/50000]\n",
            "loss: 2.834804  [32032/50000]\n",
            "loss: 2.479895  [35232/50000]\n",
            "loss: 2.767280  [38432/50000]\n",
            "loss: 2.989675  [41632/50000]\n",
            "loss: 3.163738  [44832/50000]\n",
            "loss: 2.583569  [48032/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.4%, Avg loss: 3.097482 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv-snum",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}